test Maximum Entropy classifer for class induction
training data is loaded!
gazetteers are loaded!
skip computing features...
load features from 'trainWithFeatures.json'... 
train set size 2134
 split  70.0 % from gold standards for training ... 
start [1] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.094
             2          -0.17992        0.906
             3          -0.17729        0.906
             4          -0.17374        0.906
             5          -0.16993        0.906
             6          -0.16605        0.906
             7          -0.16217        0.906
             8          -0.15833        0.906
             9          -0.15458        0.906
            10          -0.15092        0.906
            11          -0.14738        0.906
            12          -0.14396        0.906
            13          -0.14068        0.906
            14          -0.13754        0.908
            15          -0.13452        0.911
            16          -0.13164        0.914
            17          -0.12889        0.917
            18          -0.12626        0.924
            19          -0.12374        0.928
            20          -0.12134        0.931
            21          -0.11905        0.934
            22          -0.11685        0.939
            23          -0.11475        0.943
            24          -0.11274        0.944
            25          -0.11081        0.948
            26          -0.10897        0.950
            27          -0.10720        0.950
            28          -0.10549        0.952
            29          -0.10386        0.954
            30          -0.10229        0.954
            31          -0.10078        0.955
            32          -0.09932        0.956
            33          -0.09791        0.957
            34          -0.09656        0.958
            35          -0.09525        0.960
            36          -0.09399        0.961
            37          -0.09277        0.964
            38          -0.09159        0.964
            39          -0.09044        0.965
            40          -0.08934        0.965
            41          -0.08826        0.965
            42          -0.08722        0.965
            43          -0.08621        0.966
            44          -0.08523        0.966
            45          -0.08428        0.967
            46          -0.08335        0.968
            47          -0.08245        0.969
            48          -0.08157        0.970
            49          -0.08072        0.970
            50          -0.07989        0.970
            51          -0.07908        0.973
            52          -0.07829        0.974
            53          -0.07752        0.975
            54          -0.07677        0.975
            55          -0.07603        0.976
            56          -0.07531        0.976
            57          -0.07461        0.977
            58          -0.07393        0.977
            59          -0.07326        0.977
            60          -0.07261        0.977
            61          -0.07196        0.977
            62          -0.07134        0.977
            63          -0.07072        0.978
            64          -0.07012        0.978
            65          -0.06953        0.981
            66          -0.06896        0.982
            67          -0.06839        0.982
            68          -0.06783        0.982
            69          -0.06729        0.982
            70          -0.06676        0.982
            71          -0.06623        0.982
            72          -0.06572        0.983
            73          -0.06521        0.983
            74          -0.06471        0.985
            75          -0.06423        0.985
            76          -0.06375        0.985
            77          -0.06328        0.985
            78          -0.06281        0.985
            79          -0.06236        0.985
            80          -0.06191        0.986
            81          -0.06147        0.986
            82          -0.06104        0.986
            83          -0.06061        0.986
            84          -0.06019        0.986
            85          -0.05978        0.987
            86          -0.05938        0.987
            87          -0.05898        0.987
            88          -0.05858        0.987
            89          -0.05819        0.987
            90          -0.05781        0.988
            91          -0.05744        0.989
            92          -0.05707        0.989
            93          -0.05670        0.989
            94          -0.05634        0.989
            95          -0.05598        0.989
            96          -0.05563        0.989
            97          -0.05529        0.989
            98          -0.05495        0.989
            99          -0.05461        0.989
         Final          -0.05428        0.989
accuracy: 0.9484375
precision: 0.9069767441860465
recall: 0.5735294117647058
F-measure: 0.7027027027027026
========Show top 10 most informative features========
  -2.793 last_2_letters=='None' and label is 'class'
   2.039 word_root=='Music' and label is 'class'
   1.969 next_1_word_last_2_letters=='da' and label is 'class'
   1.959 word_root=='Dance' and label is 'class'
   1.736 word_root=='sinkhole' and label is 'class'
  -1.529 next_1_word_pos=='DT' and label is 'class'
   1.460 word_root=='competition' and label is 'class'
   1.448 prev_3_word_last_2_letters=='th' and label is 'class'
   1.405 word_root=='actor' and label is 'class'
   1.398 word_root=='Major' and label is 'class'
start [2] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.100
             2          -0.19095        0.900
             3          -0.18732        0.900
             4          -0.18299        0.900
             5          -0.17846        0.900
             6          -0.17390        0.900
             7          -0.16937        0.900
             8          -0.16494        0.900
             9          -0.16064        0.900
            10          -0.15649        0.900
            11          -0.15250        0.900
            12          -0.14869        0.901
            13          -0.14504        0.904
            14          -0.14157        0.907
            15          -0.13827        0.911
            16          -0.13512        0.918
            17          -0.13213        0.921
            18          -0.12929        0.928
            19          -0.12658        0.934
            20          -0.12401        0.936
            21          -0.12155        0.942
            22          -0.11921        0.945
            23          -0.11698        0.948
            24          -0.11485        0.951
            25          -0.11281        0.953
            26          -0.11087        0.954
            27          -0.10900        0.958
            28          -0.10721        0.959
            29          -0.10550        0.960
            30          -0.10385        0.960
            31          -0.10227        0.960
            32          -0.10075        0.961
            33          -0.09929        0.963
            34          -0.09787        0.962
            35          -0.09651        0.962
            36          -0.09520        0.963
            37          -0.09393        0.965
            38          -0.09270        0.966
            39          -0.09152        0.967
            40          -0.09037        0.969
            41          -0.08926        0.970
            42          -0.08818        0.970
            43          -0.08714        0.972
            44          -0.08612        0.972
            45          -0.08514        0.972
            46          -0.08418        0.973
            47          -0.08325        0.973
            48          -0.08235        0.973
            49          -0.08147        0.973
            50          -0.08061        0.973
            51          -0.07978        0.973
            52          -0.07896        0.974
            53          -0.07817        0.975
            54          -0.07740        0.976
            55          -0.07664        0.976
            56          -0.07591        0.978
            57          -0.07519        0.978
            58          -0.07448        0.978
            59          -0.07380        0.979
            60          -0.07312        0.979
            61          -0.07247        0.979
            62          -0.07183        0.979
            63          -0.07120        0.981
            64          -0.07058        0.981
            65          -0.06998        0.981
            66          -0.06939        0.981
            67          -0.06881        0.982
            68          -0.06824        0.983
            69          -0.06769        0.983
            70          -0.06714        0.983
            71          -0.06661        0.983
            72          -0.06608        0.984
            73          -0.06557        0.984
            74          -0.06506        0.985
            75          -0.06457        0.985
            76          -0.06408        0.985
            77          -0.06360        0.985
            78          -0.06313        0.985
            79          -0.06267        0.985
            80          -0.06222        0.986
            81          -0.06177        0.987
            82          -0.06133        0.987
            83          -0.06090        0.987
            84          -0.06048        0.988
            85          -0.06006        0.988
            86          -0.05965        0.988
            87          -0.05925        0.988
            88          -0.05885        0.988
            89          -0.05846        0.988
            90          -0.05807        0.988
            91          -0.05769        0.988
            92          -0.05732        0.988
            93          -0.05695        0.988
            94          -0.05659        0.988
            95          -0.05623        0.988
            96          -0.05588        0.989
            97          -0.05553        0.989
            98          -0.05519        0.989
            99          -0.05485        0.989
         Final          -0.05452        0.989
accuracy: 0.9421875
precision: 0.775
recall: 0.5254237288135594
F-measure: 0.6262626262626263
========Show top 10 most informative features========
  -2.080 last_2_letters=='None' and label is 'class'
   1.922 word_root=='Dance' and label is 'class'
   1.900 word_root=='Formula' and label is 'class'
   1.803 prev_3_word_last_2_letters=='it' and label is 'class'
   1.803 word_root=='sinkhole' and label is 'class'
   1.706 next_1_word_last_2_letters=='da' and label is 'class'
   1.622 word_root=='actor' and label is 'class'
   1.598 word_root=='racer' and label is 'class'
   1.555 word_root=='One' and label is 'class'
   1.555 prev_1_word_last_2_letters=='la' and label is 'class'
start [3] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.098
             2          -0.18826        0.902
             3          -0.18486        0.902
             4          -0.18085        0.902
             5          -0.17665        0.902
             6          -0.17241        0.902
             7          -0.16819        0.902
             8          -0.16404        0.902
             9          -0.15999        0.902
            10          -0.15606        0.902
            11          -0.15227        0.902
            12          -0.14862        0.902
            13          -0.14512        0.902
            14          -0.14177        0.906
            15          -0.13857        0.908
            16          -0.13551        0.912
            17          -0.13258        0.916
            18          -0.12979        0.922
            19          -0.12713        0.928
            20          -0.12459        0.931
            21          -0.12216        0.933
            22          -0.11983        0.934
            23          -0.11761        0.940
            24          -0.11549        0.944
            25          -0.11345        0.946
            26          -0.11150        0.948
            27          -0.10963        0.950
            28          -0.10783        0.956
            29          -0.10611        0.957
            30          -0.10445        0.959
            31          -0.10285        0.961
            32          -0.10132        0.963
            33          -0.09983        0.963
            34          -0.09840        0.965
            35          -0.09703        0.965
            36          -0.09569        0.965
            37          -0.09441        0.967
            38          -0.09316        0.969
            39          -0.09195        0.969
            40          -0.09079        0.970
            41          -0.08965        0.971
            42          -0.08856        0.971
            43          -0.08749        0.972
            44          -0.08646        0.972
            45          -0.08545        0.972
            46          -0.08448        0.972
            47          -0.08353        0.973
            48          -0.08261        0.973
            49          -0.08171        0.973
            50          -0.08083        0.973
            51          -0.07998        0.973
            52          -0.07915        0.973
            53          -0.07833        0.973
            54          -0.07754        0.974
            55          -0.07677        0.974
            56          -0.07602        0.975
            57          -0.07528        0.978
            58          -0.07456        0.978
            59          -0.07385        0.978
            60          -0.07317        0.978
            61          -0.07249        0.979
            62          -0.07183        0.981
            63          -0.07119        0.981
            64          -0.07056        0.981
            65          -0.06994        0.981
            66          -0.06933        0.982
            67          -0.06874        0.982
            68          -0.06815        0.983
            69          -0.06758        0.983
            70          -0.06702        0.984
            71          -0.06647        0.985
            72          -0.06593        0.985
            73          -0.06540        0.985
            74          -0.06488        0.985
            75          -0.06437        0.985
            76          -0.06387        0.985
            77          -0.06338        0.986
            78          -0.06289        0.986
            79          -0.06242        0.986
            80          -0.06195        0.986
            81          -0.06149        0.986
            82          -0.06104        0.986
            83          -0.06059        0.987
            84          -0.06016        0.987
            85          -0.05972        0.987
            86          -0.05930        0.988
            87          -0.05888        0.989
            88          -0.05847        0.989
            89          -0.05807        0.989
            90          -0.05767        0.989
            91          -0.05728        0.990
            92          -0.05689        0.990
            93          -0.05651        0.991
            94          -0.05613        0.991
            95          -0.05576        0.991
            96          -0.05540        0.991
            97          -0.05504        0.991
            98          -0.05469        0.991
            99          -0.05434        0.992
         Final          -0.05399        0.993
accuracy: 0.9484375
precision: 0.8918918918918919
recall: 0.532258064516129
F-measure: 0.6666666666666666
========Show top 10 most informative features========
   2.255 word_root=='Electronic' and label is 'class'
  -1.995 last_2_letters=='None' and label is 'class'
   1.859 word_root=='name' and label is 'class'
   1.772 word_root=='Dance' and label is 'class'
   1.667 word_root=='Music' and label is 'class'
  -1.638 word_root=='year' and label is 'O'
   1.591 word_root=='racer' and label is 'class'
   1.591 word_root=='actor' and label is 'class'
   1.566 next_1_word_last_2_letters=='da' and label is 'class'
  -1.346 word_pos=='IN' and label is 'class'
start [4] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.101
             2          -0.19263        0.899
             3          -0.18919        0.899
             4          -0.18507        0.899
             5          -0.18076        0.899
             6          -0.17643        0.899
             7          -0.17215        0.899
             8          -0.16795        0.899
             9          -0.16387        0.899
            10          -0.15993        0.899
            11          -0.15613        0.899
            12          -0.15247        0.899
            13          -0.14898        0.900
            14          -0.14563        0.903
            15          -0.14243        0.906
            16          -0.13937        0.911
            17          -0.13646        0.918
            18          -0.13367        0.922
            19          -0.13101        0.924
            20          -0.12847        0.930
            21          -0.12604        0.933
            22          -0.12372        0.939
            23          -0.12149        0.940
            24          -0.11937        0.942
            25          -0.11733        0.946
            26          -0.11537        0.948
            27          -0.11350        0.950
            28          -0.11170        0.951
            29          -0.10996        0.953
            30          -0.10830        0.955
            31          -0.10669        0.956
            32          -0.10515        0.956
            33          -0.10366        0.957
            34          -0.10222        0.959
            35          -0.10083        0.959
            36          -0.09949        0.960
            37          -0.09820        0.961
            38          -0.09694        0.962
            39          -0.09573        0.965
            40          -0.09455        0.966
            41          -0.09341        0.967
            42          -0.09231        0.968
            43          -0.09123        0.969
            44          -0.09019        0.969
            45          -0.08918        0.971
            46          -0.08819        0.971
            47          -0.08723        0.971
            48          -0.08630        0.972
            49          -0.08539        0.973
            50          -0.08451        0.973
            51          -0.08365        0.974
            52          -0.08281        0.975
            53          -0.08199        0.976
            54          -0.08119        0.977
            55          -0.08041        0.977
            56          -0.07965        0.977
            57          -0.07890        0.977
            58          -0.07818        0.977
            59          -0.07746        0.977
            60          -0.07677        0.977
            61          -0.07609        0.977
            62          -0.07542        0.979
            63          -0.07477        0.980
            64          -0.07413        0.980
            65          -0.07351        0.981
            66          -0.07289        0.981
            67          -0.07229        0.982
            68          -0.07170        0.982
            69          -0.07113        0.982
            70          -0.07056        0.983
            71          -0.07000        0.983
            72          -0.06946        0.983
            73          -0.06892        0.983
            74          -0.06840        0.985
            75          -0.06788        0.985
            76          -0.06737        0.985
            77          -0.06688        0.985
            78          -0.06639        0.985
            79          -0.06591        0.985
            80          -0.06543        0.986
            81          -0.06497        0.986
            82          -0.06451        0.986
            83          -0.06406        0.986
            84          -0.06362        0.987
            85          -0.06318        0.987
            86          -0.06275        0.987
            87          -0.06233        0.987
            88          -0.06192        0.987
            89          -0.06151        0.987
            90          -0.06110        0.987
            91          -0.06071        0.987
            92          -0.06032        0.987
            93          -0.05993        0.987
            94          -0.05955        0.987
            95          -0.05918        0.987
            96          -0.05881        0.987
            97          -0.05845        0.988
            98          -0.05809        0.989
            99          -0.05773        0.989
         Final          -0.05739        0.989
accuracy: 0.94375
precision: 0.7619047619047619
recall: 0.5517241379310345
F-measure: 0.64
========Show top 10 most informative features========
  -2.029 last_2_letters=='None' and label is 'class'
   1.994 word_root=='Electronic' and label is 'class'
   1.819 word_root=='actor' and label is 'class'
   1.811 word_root=='Formula' and label is 'class'
   1.792 word_root=='One' and label is 'class'
   1.792 prev_1_word_last_2_letters=='la' and label is 'class'
   1.672 prev_1_word_last_2_letters=='ho' and label is 'class'
   1.607 next_1_word_last_2_letters=='da' and label is 'class'
   1.580 word_root=='sinkhole' and label is 'class'
  -1.576 word_pos=='IN' and label is 'class'
start [5] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.096
             2          -0.18210        0.904
             3          -0.17893        0.904
             4          -0.17507        0.904
             5          -0.17099        0.904
             6          -0.16684        0.904
             7          -0.16271        0.904
             8          -0.15864        0.904
             9          -0.15466        0.904
            10          -0.15081        0.904
            11          -0.14708        0.904
            12          -0.14350        0.904
            13          -0.14006        0.905
            14          -0.13677        0.908
            15          -0.13362        0.910
            16          -0.13061        0.914
            17          -0.12774        0.918
            18          -0.12501        0.923
            19          -0.12239        0.926
            20          -0.11990        0.930
            21          -0.11752        0.936
            22          -0.11524        0.944
            23          -0.11306        0.948
            24          -0.11098        0.950
            25          -0.10899        0.952
            26          -0.10708        0.955
            27          -0.10525        0.957
            28          -0.10350        0.958
            29          -0.10181        0.959
            30          -0.10019        0.959
            31          -0.09863        0.961
            32          -0.09713        0.961
            33          -0.09568        0.961
            34          -0.09429        0.962
            35          -0.09294        0.963
            36          -0.09165        0.965
            37          -0.09039        0.966
            38          -0.08918        0.966
            39          -0.08800        0.967
            40          -0.08687        0.967
            41          -0.08577        0.968
            42          -0.08470        0.969
            43          -0.08367        0.971
            44          -0.08266        0.971
            45          -0.08169        0.973
            46          -0.08074        0.975
            47          -0.07982        0.976
            48          -0.07893        0.976
            49          -0.07805        0.976
            50          -0.07721        0.977
            51          -0.07638        0.977
            52          -0.07558        0.977
            53          -0.07479        0.977
            54          -0.07403        0.978
            55          -0.07328        0.979
            56          -0.07255        0.979
            57          -0.07184        0.979
            58          -0.07115        0.980
            59          -0.07047        0.981
            60          -0.06981        0.981
            61          -0.06916        0.981
            62          -0.06853        0.981
            63          -0.06791        0.981
            64          -0.06730        0.983
            65          -0.06671        0.983
            66          -0.06613        0.983
            67          -0.06556        0.984
            68          -0.06500        0.984
            69          -0.06445        0.984
            70          -0.06392        0.984
            71          -0.06339        0.984
            72          -0.06288        0.984
            73          -0.06237        0.984
            74          -0.06187        0.984
            75          -0.06139        0.985
            76          -0.06091        0.985
            77          -0.06044        0.985
            78          -0.05998        0.985
            79          -0.05952        0.985
            80          -0.05908        0.985
            81          -0.05864        0.987
            82          -0.05821        0.987
            83          -0.05779        0.988
            84          -0.05737        0.988
            85          -0.05697        0.989
            86          -0.05656        0.989
            87          -0.05617        0.989
            88          -0.05578        0.989
            89          -0.05540        0.989
            90          -0.05502        0.989
            91          -0.05465        0.989
            92          -0.05428        0.990
            93          -0.05392        0.990
            94          -0.05357        0.991
            95          -0.05322        0.991
            96          -0.05288        0.991
            97          -0.05254        0.991
            98          -0.05220        0.991
            99          -0.05187        0.991
         Final          -0.05155        0.991
accuracy: 0.94375
precision: 0.8947368421052632
recall: 0.5151515151515151
F-measure: 0.6538461538461539
========Show top 10 most informative features========
  -2.733 last_2_letters=='None' and label is 'class'
   2.054 word_root=='Electronic' and label is 'class'
   1.919 next_1_word_last_2_letters=='da' and label is 'class'
  -1.654 word_root=='year' and label is 'O'
  -1.641 next_1_word_pos=='DT' and label is 'class'
   1.628 word_root=='anthem' and label is 'class'
   1.513 word_root=='Music' and label is 'class'
   1.511 prev_3_word_last_2_letters=='th' and label is 'class'
   1.472 word_root=='Major' and label is 'class'
   1.470 word_root=='cultural' and label is 'class'
start [6] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.094
             2          -0.17794        0.906
             3          -0.17492        0.906
             4          -0.17116        0.906
             5          -0.16716        0.906
             6          -0.16311        0.906
             7          -0.15907        0.906
             8          -0.15511        0.906
             9          -0.15124        0.906
            10          -0.14750        0.906
            11          -0.14389        0.906
            12          -0.14043        0.906
            13          -0.13711        0.907
            14          -0.13393        0.908
            15          -0.13090        0.912
            16          -0.12801        0.918
            17          -0.12525        0.923
            18          -0.12262        0.926
            19          -0.12011        0.929
            20          -0.11772        0.935
            21          -0.11544        0.940
            22          -0.11326        0.945
            23          -0.11118        0.948
            24          -0.10918        0.950
            25          -0.10728        0.952
            26          -0.10545        0.956
            27          -0.10370        0.956
            28          -0.10202        0.956
            29          -0.10041        0.959
            30          -0.09886        0.961
            31          -0.09736        0.961
            32          -0.09593        0.964
            33          -0.09454        0.965
            34          -0.09321        0.967
            35          -0.09192        0.968
            36          -0.09068        0.968
            37          -0.08947        0.969
            38          -0.08831        0.969
            39          -0.08718        0.969
            40          -0.08609        0.970
            41          -0.08504        0.971
            42          -0.08401        0.973
            43          -0.08302        0.973
            44          -0.08205        0.973
            45          -0.08112        0.973
            46          -0.08021        0.975
            47          -0.07932        0.975
            48          -0.07846        0.975
            49          -0.07762        0.976
            50          -0.07680        0.976
            51          -0.07601        0.976
            52          -0.07523        0.977
            53          -0.07448        0.977
            54          -0.07374        0.979
            55          -0.07302        0.980
            56          -0.07232        0.981
            57          -0.07163        0.981
            58          -0.07096        0.981
            59          -0.07030        0.983
            60          -0.06966        0.985
            61          -0.06904        0.985
            62          -0.06842        0.986
            63          -0.06782        0.986
            64          -0.06723        0.987
            65          -0.06666        0.987
            66          -0.06610        0.987
            67          -0.06554        0.987
            68          -0.06500        0.988
            69          -0.06447        0.989
            70          -0.06395        0.989
            71          -0.06344        0.989
            72          -0.06294        0.989
            73          -0.06245        0.989
            74          -0.06197        0.989
            75          -0.06149        0.989
            76          -0.06103        0.989
            77          -0.06057        0.989
            78          -0.06012        0.989
            79          -0.05968        0.989
            80          -0.05925        0.989
            81          -0.05882        0.989
            82          -0.05840        0.989
            83          -0.05799        0.989
            84          -0.05758        0.989
            85          -0.05718        0.989
            86          -0.05679        0.989
            87          -0.05641        0.989
            88          -0.05603        0.989
            89          -0.05565        0.989
            90          -0.05528        0.989
            91          -0.05492        0.989
            92          -0.05456        0.989
            93          -0.05421        0.989
            94          -0.05386        0.989
            95          -0.05352        0.989
            96          -0.05319        0.990
            97          -0.05285        0.990
            98          -0.05253        0.990
            99          -0.05220        0.990
         Final          -0.05189        0.990
accuracy: 0.9390625
precision: 0.9411764705882353
recall: 0.463768115942029
F-measure: 0.6213592233009708
========Show top 10 most informative features========
   2.471 word_root=='Electronic' and label is 'class'
   2.043 next_1_word_last_2_letters=='da' and label is 'class'
  -1.925 last_2_letters=='None' and label is 'class'
   1.813 word_root=='Music' and label is 'class'
   1.636 word_root=='Formula' and label is 'class'
  -1.583 word_pos=='IN' and label is 'class'
   1.555 word_root=='site' and label is 'class'
   1.543 word_root=='competition' and label is 'class'
  -1.502 word_pos=='DT' and label is 'class'
   1.500 word_root=='fortress' and label is 'class'
start [7] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.092
             2          -0.17609        0.908
             3          -0.17295        0.908
             4          -0.16915        0.908
             5          -0.16515        0.908
             6          -0.16109        0.908
             7          -0.15706        0.908
             8          -0.15309        0.908
             9          -0.14923        0.908
            10          -0.14548        0.908
            11          -0.14187        0.908
            12          -0.13840        0.908
            13          -0.13507        0.909
            14          -0.13189        0.912
            15          -0.12886        0.916
            16          -0.12596        0.919
            17          -0.12320        0.924
            18          -0.12057        0.928
            19          -0.11806        0.932
            20          -0.11566        0.938
            21          -0.11338        0.944
            22          -0.11120        0.945
            23          -0.10912        0.947
            24          -0.10712        0.951
            25          -0.10522        0.954
            26          -0.10339        0.956
            27          -0.10164        0.957
            28          -0.09997        0.959
            29          -0.09835        0.961
            30          -0.09680        0.962
            31          -0.09531        0.964
            32          -0.09388        0.964
            33          -0.09250        0.964
            34          -0.09116        0.965
            35          -0.08988        0.965
            36          -0.08864        0.966
            37          -0.08744        0.967
            38          -0.08627        0.967
            39          -0.08515        0.969
            40          -0.08406        0.969
            41          -0.08300        0.970
            42          -0.08198        0.971
            43          -0.08099        0.971
            44          -0.08002        0.971
            45          -0.07909        0.971
            46          -0.07817        0.973
            47          -0.07729        0.975
            48          -0.07642        0.975
            49          -0.07558        0.975
            50          -0.07477        0.975
            51          -0.07397        0.976
            52          -0.07319        0.977
            53          -0.07243        0.978
            54          -0.07169        0.978
            55          -0.07097        0.978
            56          -0.07027        0.979
            57          -0.06958        0.979
            58          -0.06890        0.979
            59          -0.06824        0.981
            60          -0.06760        0.982
            61          -0.06697        0.982
            62          -0.06635        0.982
            63          -0.06575        0.983
            64          -0.06516        0.983
            65          -0.06458        0.983
            66          -0.06401        0.983
            67          -0.06346        0.984
            68          -0.06291        0.984
            69          -0.06238        0.985
            70          -0.06186        0.985
            71          -0.06134        0.985
            72          -0.06084        0.985
            73          -0.06034        0.985
            74          -0.05986        0.986
            75          -0.05938        0.986
            76          -0.05891        0.987
            77          -0.05845        0.987
            78          -0.05800        0.987
            79          -0.05755        0.987
            80          -0.05712        0.987
            81          -0.05669        0.987
            82          -0.05627        0.987
            83          -0.05585        0.989
            84          -0.05544        0.989
            85          -0.05504        0.989
            86          -0.05465        0.989
            87          -0.05426        0.989
            88          -0.05387        0.989
            89          -0.05350        0.989
            90          -0.05313        0.989
            91          -0.05276        0.990
            92          -0.05240        0.991
            93          -0.05205        0.991
            94          -0.05170        0.991
            95          -0.05135        0.991
            96          -0.05101        0.991
            97          -0.05068        0.991
            98          -0.05035        0.991
            99          -0.05003        0.991
         Final          -0.04971        0.991
accuracy: 0.9296875
precision: 0.8461538461538461
recall: 0.4583333333333333
F-measure: 0.5945945945945945
========Show top 10 most informative features========
  -2.531 last_2_letters=='None' and label is 'class'
   2.302 word_root=='Electronic' and label is 'class'
   2.109 next_1_word_last_2_letters=='x1' and label is 'class'
   1.739 prev_1_word_last_2_letters=='0s' and label is 'class'
   1.620 word_root=='fortress' and label is 'class'
   1.597 next_1_word_last_2_letters=='ry' and label is 'class'
   1.538 word_root=='cultural' and label is 'class'
   1.498 prev_3_word_last_2_letters=='it' and label is 'class'
   1.498 word_root=='sinkhole' and label is 'class'
   1.484 word_root=='artist' and label is 'class'
start [8] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.090
             2          -0.17135        0.910
             3          -0.16900        0.910
             4          -0.16574        0.910
             5          -0.16221        0.910
             6          -0.15859        0.910
             7          -0.15494        0.910
             8          -0.15132        0.910
             9          -0.14776        0.910
            10          -0.14428        0.910
            11          -0.14090        0.910
            12          -0.13763        0.910
            13          -0.13447        0.910
            14          -0.13143        0.914
            15          -0.12851        0.916
            16          -0.12571        0.918
            17          -0.12302        0.922
            18          -0.12045        0.924
            19          -0.11798        0.926
            20          -0.11562        0.932
            21          -0.11336        0.937
            22          -0.11120        0.938
            23          -0.10912        0.942
            24          -0.10713        0.946
            25          -0.10522        0.948
            26          -0.10338        0.952
            27          -0.10162        0.954
            28          -0.09993        0.956
            29          -0.09829        0.957
            30          -0.09672        0.961
            31          -0.09521        0.962
            32          -0.09375        0.964
            33          -0.09234        0.964
            34          -0.09098        0.965
            35          -0.08967        0.968
            36          -0.08840        0.969
            37          -0.08717        0.969
            38          -0.08599        0.969
            39          -0.08484        0.970
            40          -0.08372        0.970
            41          -0.08264        0.970
            42          -0.08159        0.971
            43          -0.08057        0.971
            44          -0.07958        0.971
            45          -0.07862        0.971
            46          -0.07769        0.971
            47          -0.07678        0.972
            48          -0.07590        0.973
            49          -0.07504        0.973
            50          -0.07420        0.974
            51          -0.07338        0.976
            52          -0.07258        0.977
            53          -0.07181        0.979
            54          -0.07105        0.981
            55          -0.07031        0.982
            56          -0.06959        0.982
            57          -0.06889        0.983
            58          -0.06820        0.983
            59          -0.06753        0.983
            60          -0.06687        0.983
            61          -0.06623        0.983
            62          -0.06560        0.983
            63          -0.06498        0.985
            64          -0.06438        0.984
            65          -0.06379        0.984
            66          -0.06322        0.984
            67          -0.06265        0.984
            68          -0.06210        0.984
            69          -0.06155        0.985
            70          -0.06102        0.985
            71          -0.06050        0.985
            72          -0.05999        0.985
            73          -0.05949        0.986
            74          -0.05899        0.986
            75          -0.05851        0.986
            76          -0.05804        0.986
            77          -0.05757        0.986
            78          -0.05711        0.987
            79          -0.05667        0.987
            80          -0.05622        0.987
            81          -0.05579        0.988
            82          -0.05536        0.988
            83          -0.05495        0.988
            84          -0.05453        0.988
            85          -0.05413        0.988
            86          -0.05373        0.989
            87          -0.05334        0.989
            88          -0.05295        0.989
            89          -0.05257        0.989
            90          -0.05220        0.990
            91          -0.05183        0.991
            92          -0.05147        0.991
            93          -0.05112        0.991
            94          -0.05077        0.991
            95          -0.05042        0.992
            96          -0.05008        0.992
            97          -0.04975        0.992
            98          -0.04942        0.992
            99          -0.04909        0.992
         Final          -0.04877        0.993
accuracy: 0.9265625
precision: 0.75
recall: 0.56
F-measure: 0.6412213740458016
========Show top 10 most informative features========
   2.053 word_root=='Electronic' and label is 'class'
  -2.035 last_2_letters=='None' and label is 'class'
  -1.907 prev_1_word_pos=='IN' and label is 'class'
   1.695 word_root=='racer' and label is 'class'
   1.638 prev_3_word_last_2_letters=='it' and label is 'class'
   1.638 word_root=='sinkhole' and label is 'class'
   1.592 word_root=='Dance' and label is 'class'
   1.572 prev_2_word_word_with_digits=='Y' and label is 'class'
   1.568 word_root=='actor' and label is 'class'
  -1.490 word_pos=='IN' and label is 'class'
start [9] fold validation...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.100
             2          -0.19025        0.900
             3          -0.18693        0.900
             4          -0.18304        0.900
             5          -0.17898        0.900
             6          -0.17488        0.900
             7          -0.17082        0.900
             8          -0.16684        0.900
             9          -0.16296        0.900
            10          -0.15921        0.900
            11          -0.15558        0.900
            12          -0.15210        0.902
            13          -0.14876        0.902
            14          -0.14555        0.903
            15          -0.14249        0.904
            16          -0.13956        0.910
            17          -0.13676        0.916
            18          -0.13409        0.920
            19          -0.13153        0.926
            20          -0.12909        0.930
            21          -0.12675        0.935
            22          -0.12451        0.936
            23          -0.12237        0.937
            24          -0.12032        0.938
            25          -0.11835        0.942
            26          -0.11646        0.942
            27          -0.11464        0.945
            28          -0.11290        0.949
            29          -0.11122        0.950
            30          -0.10960        0.951
            31          -0.10805        0.952
            32          -0.10654        0.954
            33          -0.10509        0.955
            34          -0.10369        0.956
            35          -0.10234        0.958
            36          -0.10103        0.959
            37          -0.09976        0.959
            38          -0.09853        0.959
            39          -0.09734        0.962
            40          -0.09619        0.965
            41          -0.09507        0.966
            42          -0.09398        0.966
            43          -0.09293        0.966
            44          -0.09190        0.967
            45          -0.09090        0.967
            46          -0.08993        0.969
            47          -0.08898        0.971
            48          -0.08806        0.972
            49          -0.08716        0.973
            50          -0.08629        0.973
            51          -0.08543        0.973
            52          -0.08460        0.975
            53          -0.08378        0.975
            54          -0.08299        0.975
            55          -0.08221        0.976
            56          -0.08145        0.976
            57          -0.08071        0.976
            58          -0.07998        0.976
            59          -0.07927        0.977
            60          -0.07858        0.977
            61          -0.07790        0.977
            62          -0.07723        0.979
            63          -0.07658        0.979
            64          -0.07594        0.979
            65          -0.07531        0.979
            66          -0.07469        0.980
            67          -0.07409        0.981
            68          -0.07350        0.982
            69          -0.07292        0.982
            70          -0.07235        0.982
            71          -0.07179        0.983
            72          -0.07124        0.983
            73          -0.07070        0.984
            74          -0.07017        0.984
            75          -0.06964        0.984
            76          -0.06913        0.985
            77          -0.06863        0.986
            78          -0.06813        0.986
            79          -0.06765        0.987
            80          -0.06717        0.987
            81          -0.06670        0.987
            82          -0.06623        0.987
            83          -0.06578        0.987
            84          -0.06533        0.987
            85          -0.06488        0.987
            86          -0.06445        0.987
            87          -0.06402        0.987
            88          -0.06360        0.987
            89          -0.06318        0.988
            90          -0.06277        0.988
            91          -0.06237        0.988
            92          -0.06197        0.988
            93          -0.06158        0.988
            94          -0.06119        0.988
            95          -0.06081        0.988
            96          -0.06043        0.989
            97          -0.06006        0.989
            98          -0.05970        0.989
            99          -0.05934        0.989
         Final          -0.05898        0.989
accuracy: 0.959375
precision: 0.9047619047619048
recall: 0.6333333333333333
F-measure: 0.7450980392156863
========Show top 10 most informative features========
  -2.047 last_2_letters=='None' and label is 'class'
   1.979 word_root=='Electronic' and label is 'class'
   1.847 next_1_word_last_2_letters=='da' and label is 'class'
   1.800 word_root=='fortress' and label is 'class'
   1.739 word_root=='Music' and label is 'class'
   1.724 word_root=='Dance' and label is 'class'
   1.641 word_root=='sinkhole' and label is 'class'
   1.496 word_root=='competition' and label is 'class'
  -1.473 word_pos=='IN' and label is 'class'
   1.470 prev_3_word_last_2_letters=='th' and label is 'class'
all_f_measure, [0.7027027027027026, 0.6262626262626263, 0.6666666666666666, 0.64, 0.6538461538461539, 0.6213592233009708, 0.5945945945945945, 0.6412213740458016, 0.7450980392156863]
all_precision, [0.9069767441860465, 0.775, 0.8918918918918919, 0.7619047619047619, 0.8947368421052632, 0.9411764705882353, 0.8461538461538461, 0.75, 0.9047619047619048]
all_recall [0.5735294117647058, 0.5254237288135594, 0.532258064516129, 0.5517241379310345, 0.5151515151515151, 0.463768115942029, 0.4583333333333333, 0.56, 0.6333333333333333]
Final F-measure 0.6546390422928003
Final precision 0.8525113846213278
Final recall 0.534835737865071
